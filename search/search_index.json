{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>raggy</code> - a scraping and querying library","text":""},{"location":"#shhhhhh-im-just-here-for-the-code","title":"shhhhhh... I'm just here for the code","text":"<p><pre><code>pip install raggy\n</code></pre> see the tutorial for a quick start</p>"},{"location":"#what-is-this-rag-thing-people-keep-talking-about","title":"What is this RAG thing people keep talking about?","text":"<p>R.A.G. stands for Retrieval Augmented Generation. Enough hot air has been blown about it, so just read this if you're not sure what it is.</p>"},{"location":"#why-is-it-useful","title":"Why is it useful?","text":"<p>Large language models are trained on discrete data sets, at points in time. They do not update their knowledge sources inherently.  Humans want LLMs to know about their data, right now.</p>"},{"location":"#what-does-raggy-do","title":"What does <code>raggy</code> do?","text":""},{"location":"#non-technical","title":"Non-technical","text":"<ul> <li>efficiently scrape data from the web into rich documents</li> <li>throw these documents into a place where they're grouped by similarity and labelled with metadata</li> <li>retrieve documents from this place on command, based on similarity to a query or specific metadata (e.g. dates, authors, etc.)</li> </ul>"},{"location":"#more-technical","title":"More technical","text":"<ul> <li>coerce arbitrary data formats into a list of <code>Document</code> objects, possibly enriched with metadata</li> <li>upsert these <code>Document</code> objects into a vectorstore like <code>Chroma</code> or <code>Turbopuffer</code></li> <li>expose human / LLM-friendly query interfaces to these vectorstores that allow metadata filtering</li> </ul>"},{"location":"contributing/","title":"Contributing to Raggy","text":"<p>We love your input! We want to make contributing to Raggy as easy and transparent as possible.</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<p>We recommend using uv for Python environment management and package installation:</p> <pre><code># Install uv\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Clone the repo\ngit clone https://github.com/zzstoatzz/raggy.git\ncd raggy\n\n# Create and activate a virtual environment\nuv venv --python 3.12 &amp;&amp; source .venv/bin/activate\n\n# Install in editable mode with dev dependencies\nuv sync -U\n</code></pre>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code>uv run pytest\n</code></pre>"},{"location":"contributing/#building-documentation","title":"Building Documentation","text":"<pre><code>uv run mkdocs serve\n</code></pre>"},{"location":"contributing/#code-style","title":"Code Style","text":"<pre><code>uv run pre-commit install\nuv run pre-commit run --all-files # happens automatically on commit\n</code></pre>"},{"location":"contributing/#running-examples","title":"Running Examples","text":"<p>All examples can be run using uv:</p> <p>where are the dependencies?</p> <p><code>uv</code> will run the example in an isolated environment using inline script dependencies.</p> <pre><code># Run example\nuv run examples/chat_with_X/website.py\n</code></pre> <p>See our example gallery for more details.</p>"},{"location":"contributing/#versioning","title":"Versioning","text":"<p>We use Semantic Versioning. For the versions available, see the tags on this repository.</p>"},{"location":"ingest_strategy/","title":"Ingest Strategy","text":"<p>When building RAG applications, you often need to load and refresh content from multiple sources. This can involve:</p> <ul> <li>Expensive API calls</li> <li>Large document processing</li> <li>Concurrent embedding operations</li> </ul> <p>We use Prefect to handle these challenges, giving us:</p> <ul> <li>Automatic caching of expensive operations</li> <li>Concurrent processing</li> <li>Observability and retries</li> </ul> <p>Let's look at a real example that demonstrates these concepts.</p>"},{"location":"ingest_strategy/#building-a-knowledge-base","title":"Building a Knowledge Base","text":"<pre><code># /// script\n# requires-python = \"&gt;=3.10\"\n# dependencies = [\n#     \"prefect\",\n#     \"raggy[tpuf]\",\n# ]\n# ///\n\nfrom itertools import chain\nfrom datetime import timedelta\nfrom prefect import flow, task, unmapped\nfrom prefect.cache_policies import INPUTS\n\nfrom raggy.documents import Document\nfrom raggy.loaders.base import Loader\nfrom raggy.loaders.github import GitHubRepoLoader\nfrom raggy.loaders.web import SitemapLoader\nfrom raggy.vectorstores.tpuf import TurboPuffer\n\n@task(\n    cache_policy=INPUTS,\n    cache_expiration=timedelta(hours=24),\n    task_run_name=\"gather documents using {loader.__class__.__name__}\",\n    retries=2,\n)\nasync def gather_documents(loader: Loader) -&gt; list[Document]:\n    return await loader.load()\n\n@flow(flow_run_name=\"refresh knowledge in {namespace} from urls {urls} and repos {repos}\")\ndef refresh_knowledge(\n    urls: list[str] | None = None,\n    repos: list[str] | None = None,\n    include_globs: list[str] | None = None,\n    namespace: str = \"knowledge\",\n):\n\n    # Load from multiple sources\n    _2d_list_of_documents = gather_documents.map(\n        [\n            SitemapLoader(urls=urls),\n            *[\n                GitHubRepoLoader(repo=repo, include_globs=include_globs or [\"README.md\"])\n                for repo in repos\n            ],\n        ]\n    ).result()\n\n    # batch embedding and upserts to the vector store\n    with TurboPuffer(namespace=namespace) as tpuf:\n        task(tpuf.upsert_batched).submit(\n            documents=list(chain.from_iterable(_2d_list_of_documents)),\n            batch_size=unmapped(100),  # tune based on document size\n            max_concurrent=unmapped(8),  # tune based on rate limits\n        ).wait()\n\nif __name__ == \"__main__\":\n    refresh_knowledge(\n        urls=[\"https://docs.prefect.io/sitemap.xml\"],\n        repos=[\"PrefectHQ/prefect\"],\n        include_globs=[\"README.md\"],\n        namespace=\"test-knowledge\",\n    )\n</code></pre> <p>This example shows key patterns:</p> <ol> <li>Automatic retries for resilience</li> <li>Concurrent processing</li> <li>Efficient batching of embedding operations</li> </ol> <p>See the refresh examples for complete implementations using both Chroma and TurboPuffer.</p>"},{"location":"ingest_strategy/#performance-tips","title":"Performance Tips","text":"<p>For production workloads: <pre><code>@task(\n    retries=2,\n    retry_delay_seconds=[3, 60],  # exponential backoff\n    cache_expiration=timedelta(days=1),\n    cache_policy=INPUTS,  # for example, hash based on provided parameters\n    persist_result=True,  # save results to storage\n)\nasync def gather_documents(loader: Loader) -&gt; list[Document]:\n    return await loader.load()\n</code></pre></p> <p>See Prefect's documentation for more on task configuration and caching strategies.</p>"},{"location":"api_reference/","title":"Overview","text":"<p>Here you'll find the main offerings of the <code>raggy</code> library, which include:</p> <ul> <li>Loaders</li> <li>Vectorstore abstractions</li> <li>Utilities</li> </ul> <p>Warning</p> <p>These are subject to change as the library evolves (especially the utilities).</p>"},{"location":"api_reference/settings/","title":"Settings","text":""},{"location":"api_reference/settings/#raggy.settings.Settings","title":"<code>Settings</code>","text":"<p>The settings for Raggy.</p> <p>Attributes:</p> Name Type Description <code>html_parser</code> <code>Callable[[str], str]</code> <p>The function to use for parsing HTML.</p> <code>log_level</code> <code>str</code> <p>The log level to use.</p> <code>log_verbose</code> <code>bool</code> <p>Whether to log verbose messages.</p> <code>openai_chat_completions_model</code> <code>str</code> <p>The OpenAI model to use for chat completions.</p> <code>openai_embeddings_model</code> <code>str</code> <p>The OpenAI model to use for creating embeddings.</p>"},{"location":"api_reference/settings/#raggy.settings.default_html_parser","title":"<code>default_html_parser</code>","text":"<p>The default HTML parser using trafilatura or bs4 as a fallback. Args:     html: The HTML to parse.</p> <p>Returns:</p> Type Description <code>str</code> <p>The parsed HTML.</p>"},{"location":"api_reference/loaders/base/","title":"Base","text":""},{"location":"api_reference/loaders/base/#raggy.loaders.base.Loader","title":"<code>Loader</code>","text":"<p>A base class for loaders.</p>"},{"location":"api_reference/loaders/base/#raggy.loaders.base.MultiLoader","title":"<code>MultiLoader</code>","text":"<p>A loader that loads from multiple loaders.</p> <p>Attributes:</p> Name Type Description <code>loaders</code> <code>list[Loader]</code> <p>The loaders to load from.</p> <p>Examples:</p> <p>Basic Usage of <code>MultiLoader</code> <pre><code>from raggy.loaders.base import MultiLoader\nfrom raggy.loaders.github import GitHubRepoLoader\n\nloader = MultiLoader(\n    loaders=[\n        GitHubRepoLoader(repo=\"prefecthq/prefect\"),\n        GitHubRepoLoader(repo=\"prefecthq/marvin\"),\n    ]\n)\n\ndocuments = await loader.load() # all (chunked) files from both repos\nprint(documents)\n</code></pre></p>"},{"location":"api_reference/loaders/github/","title":"GitHub","text":"<p>Loaders for GitHub.</p>"},{"location":"api_reference/loaders/github/#raggy.loaders.github.GitHubIssueLoader","title":"<code>GitHubIssueLoader</code>","text":"<p>Loader for GitHub issues in a given repository.</p> <p>Beware the GitHub API rate limit.</p> <p>Attributes:</p> Name Type Description <code>repo</code> <code>str</code> <p>The GitHub repository in the format 'owner/repo'.</p> <code>n_issues</code> <code>int</code> <p>The number of issues to load.</p> <code>include_comments</code> <code>bool</code> <p>Whether to include comments in the issues.</p> <code>ignore_body_after</code> <code>str</code> <p>The text to ignore in the issue body.</p> <code>ignore_users</code> <code>list[str]</code> <p>A list of users to ignore.</p> <code>use_GH_token</code> <code>bool</code> <p>Whether to use the <code>GITHUB_TOKEN</code> environment variable for authentication (recommended).</p>"},{"location":"api_reference/loaders/github/#raggy.loaders.github.GitHubIssueLoader.load","title":"<code>load</code>  <code>async</code>","text":"<p>Load all issues for the given repository.</p> <p>Returns:</p> Type Description <code>list[Document]</code> <p>A list of <code>Document</code> objects, each representing an issue.</p>"},{"location":"api_reference/loaders/github/#raggy.loaders.github.GitHubRepoLoader","title":"<code>GitHubRepoLoader</code>","text":"<p>Loader for files on GitHub that match a glob pattern.</p> <p>Attributes:</p> Name Type Description <code>repo</code> <code>str</code> <p>The GitHub repository in the format 'owner/repo'.</p> <code>include_globs</code> <code>list[str] | None</code> <p>A list of glob patterns to include.</p> <code>exclude_globs</code> <code>list[str] | None</code> <p>A list of glob patterns to exclude.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the repository is not in the format 'owner/repo'.</p> Example <p>Load all files from the <code>prefecthq/prefect</code> <pre><code>from raggy.loaders.github import GitHubRepoLoader\n\nloader = GitHubRepoLoader(repo=\"prefecthq/prefect\")\n\ndocuments = await loader.load()\nprint(documents)\n</code></pre></p>"},{"location":"api_reference/loaders/github/#raggy.loaders.github.GitHubRepoLoader.load","title":"<code>load</code>  <code>async</code>","text":"<p>Load files from GitHub that match the glob pattern.</p>"},{"location":"api_reference/loaders/github/#raggy.loaders.github.read_file_with_chardet","title":"<code>read_file_with_chardet</code>  <code>async</code>","text":"<p>Read a file with chardet to detect encoding.</p>"},{"location":"api_reference/loaders/pdf/","title":"PDF","text":""},{"location":"api_reference/loaders/pdf/#raggy.loaders.pdf.PDFLoader","title":"<code>PDFLoader</code>","text":"<p>A loader for PDF files.</p> <p>Attributes:</p> Name Type Description <code>file_path</code> <code>str</code> <p>The path to the PDF file or a URL to download the PDF from.</p> <p>Examples:</p> <p>Load a PDF file from a local path: <pre><code>from raggy.loaders.pdf import PDFLoader\n\nloader = PDFLoader(file_path=\"path/to/file.pdf\")\ndocuments = await loader.load()\nprint(documents)\n</code></pre></p> <p>Load a PDF file from a URL: <pre><code>from raggy.loaders.pdf import PDFLoader\n\nloader = PDFLoader(file_path=\"https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf\")\ndocuments = await loader.load()\nprint(documents)\n</code></pre></p>"},{"location":"api_reference/loaders/web/","title":"Web","text":""},{"location":"api_reference/loaders/web/#raggy.loaders.web.HTMLLoader","title":"<code>HTMLLoader</code>","text":"<p>A loader that loads HTML, optionally converting it to markdown or stripping tags</p>"},{"location":"api_reference/loaders/web/#raggy.loaders.web.SitemapLoader","title":"<code>SitemapLoader</code>","text":"<p>A loader that loads URLs from a sitemap. Attributes:     include: A list of strings or regular expressions. Only URLs that match one of these will be included.     exclude: A list of strings or regular expressions. URLs that match one of these will be excluded.     url_loader: The loader to use for loading the URLs.     create_excerpts: Whether to split documents into excerpts. Defaults to True.</p>"},{"location":"api_reference/loaders/web/#raggy.loaders.web.URLLoader","title":"<code>URLLoader</code>","text":"<p>Given a list of URLs, loads whatever it finds there.</p> <p>Attributes:</p> Name Type Description <code>urls</code> <code>list[str]</code> <p>The URLs to load from.</p> <code>create_excerpts</code> <code>bool</code> <p>Whether to split documents into excerpts. Defaults to True.</p>"},{"location":"api_reference/loaders/web/#raggy.loaders.web.URLLoader.response_to_document","title":"<code>response_to_document</code>  <code>async</code>","text":"<p>Convert an HTTP response to a Document.</p>"},{"location":"api_reference/utilities/asyncutils/","title":"Async","text":""},{"location":"api_reference/utilities/asyncutils/#raggy.utilities.asyncutils.run_concurrent_tasks","title":"<code>run_concurrent_tasks</code>  <code>async</code>","text":"<p>Run multiple tasks concurrently with a limit on concurrent execution.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>list[Awaitable[T]]</code> <p>List of awaitables to execute</p> required <code>max_concurrent</code> <code>int</code> <p>Maximum number of tasks to run concurrently</p> <code>max_concurrent_tasks</code>"},{"location":"api_reference/utilities/asyncutils/#raggy.utilities.asyncutils.run_sync_in_worker_thread","title":"<code>run_sync_in_worker_thread</code>  <code>async</code>","text":"<p>Runs a sync function in a new worker thread so that the main thread's event loop is not blocked.</p>"},{"location":"api_reference/utilities/collections/","title":"Collections","text":""},{"location":"api_reference/utilities/collections/#raggy.utilities.collections.batched","title":"<code>batched</code>","text":"<p>Yield batches of items from an iterable.</p> <p>If size_fn is not provided, then the batch size will be determined by the number of items in the batch.</p> <p>If size_fn is provided, then it will be used to compute the batch size. Note that if a single item is larger than the batch size, it will be returned as a batch of its own.</p> <p>Parameters:</p> Name Type Description Default <code>iterable</code> <code>Iterable[T]</code> <p>The iterable to batch</p> required <code>size</code> <code>int</code> <p>The size of the batch</p> required <code>size_fn</code> <code>Callable[[T], int] | None</code> <p>A function to compute the size of an item in the iterable</p> <code>None</code> <p>Yields:</p> Type Description <code>tuple[T, ...]</code> <p>A batch of items from the iterable</p> Example <p>Batch a list of strings by the number of characters: <pre><code>from raggy.utilities.collections import batched\n\nitems = [\n    \"foo\",\n    \"bar\",\n    \"baz\",\n    \"qux\",\n    \"quux\",\n    \"corge\",\n    \"grault\",\n    \"garply\",\n    \"waldo\",\n    \"fred\",\n    \"plugh\",\n    \"xyzzy\",\n    \"thud\",\n]\n\nbatches = list(batched(items, size=10, size_fn=len))\n\nassert batches == [\n    ('foo', 'bar', 'baz'),\n    ('qux', 'quux'),\n    ('corge',),\n    ('grault',),\n    ('garply',),\n    ('waldo', 'fred'),\n    ('plugh', 'xyzzy'),\n    ('thud',)\n]\n</code></pre></p>"},{"location":"api_reference/utilities/collections/#raggy.utilities.collections.distinct","title":"<code>distinct</code>","text":"<p>Yield distinct items from an iterable.</p> <p>Parameters:</p> Name Type Description Default <code>iterable</code> <code>Iterable[T]</code> <p>The iterable to filter</p> required <code>key</code> <code>Callable[[T], Any]</code> <p>A function to compute a key for each item</p> <code>lambda i: i</code> <p>Yields:</p> Type Description <code>T</code> <p>Distinct items from the iterable</p> Example <p>Dedupe a list of Pydantic models by a key: <pre><code>from pydantic import BaseModel\nfrom raggy.utilities.collections import distinct\n\nclass MyModel(BaseModel):\n    id: int\n    name: str\n\nitems = [\n    MyModel(id=1, name=\"foo\"),\n    MyModel(id=2, name=\"bar\"),\n    MyModel(id=1, name=\"baz\"),\n]\n\ndeduped = list(distinct(items, key=lambda i: i.id))\n\nassert deduped == [\n    MyModel(id=1, name=\"foo\"),\n    MyModel(id=2, name=\"bar\"),\n]\n</code></pre></p>"},{"location":"api_reference/utilities/embeddings/","title":"Embeddings","text":""},{"location":"api_reference/utilities/embeddings/#raggy.utilities.embeddings.create_openai_embeddings","title":"<code>create_openai_embeddings</code>  <code>async</code>","text":"<pre><code>create_openai_embeddings\n</code></pre><pre><code>create_openai_embeddings\n</code></pre> <p>Create OpenAI embeddings for a list of texts.</p> <p>Parameters:</p> Name Type Description Default <code>input_</code> <code>str | list[str] | Any</code> <p>The input text or list of texts to embed</p> required <code>timeout</code> <code>int</code> <p>The maximum time to wait for the request to complete</p> <code>60</code> <code>model</code> <code>str</code> <p>The model to use for the embeddings. Defaults to the value of <code>raggy.settings.openai_embeddings_model</code>, which is \"text-embedding-3-small\" by default</p> <code>openai_embeddings_model</code> <p>Returns:</p> Type Description <code>Embedding | list[Embedding]</code> <p>The embeddings for the input text or list of texts</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If input_ is not a str or a list of str</p> <p>Examples:</p> <p>Create an embedding for a single text: <pre><code>from raggy.utilities.embeddings import create_openai_embeddings\n\nembedding = await create_openai_embeddings(\"Hello, world!\")\n</code></pre></p> <p>Create embeddings for a list of texts: <pre><code>from raggy.utilities.embeddings import create_openai_embeddings\n\nembeddings = await create_openai_embeddings([\n    \"Hello, world!\",\n    \"Goodbye, world!\",\n])\n</code></pre></p>"},{"location":"api_reference/utilities/filesystem/","title":"Filesystem","text":""},{"location":"api_reference/utilities/filesystem/#raggy.utilities.filesystem.get_open_file_limit","title":"<code>get_open_file_limit</code>","text":"<p>Get the maximum number of open files allowed for the current process.</p> <p>Returns:</p> Type Description <code>int</code> <p>The maximum number of open files allowed for the current process.</p>"},{"location":"api_reference/utilities/filesystem/#raggy.utilities.filesystem.multi_glob","title":"<code>multi_glob</code>","text":"<p>Return a list of all files in the given directory that match the patterns in keep_globs and do not match the patterns in drop_globs. The patterns are defined using glob syntax.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str | None</code> <p>The directory to search in. If not provided, the current working directory is used.</p> <code>None</code> <code>keep_globs</code> <code>list[str] | None</code> <p>A list of glob patterns to keep.</p> <code>None</code> <code>drop_globs</code> <code>list[str] | None</code> <p>A list of glob patterns to drop.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>A list of Path objects representing the files that match the given</p> <code>list[Path]</code> <p>patterns.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the directory does not exist.</p> Example <p>Get all files (except those in the .git directory) in the current directory <pre><code>from raggy.utilities.filesystem import multi_glob\n\nfiles = multi_glob() # .git files are excluded by default (unless drop_globs is set)\n</code></pre></p> <p>Get all python files in the current directory <pre><code>from raggy.utilities.filesystem import multi_glob\n\nfiles = multi_glob(keep_globs=[\"**/*.py\"])\n</code></pre></p> <p>Get all files except those in any <code>__pycache__</code> directories <pre><code>from raggy.utilities.filesystem import multi_glob\n\nfiles = multi_glob(drop_globs=[\"**/__pycache__/**/*\"])\n</code></pre></p>"},{"location":"api_reference/utilities/ids/","title":"IDs","text":""},{"location":"api_reference/utilities/ids/#raggy.utilities.ids.generate_prefixed_uuid","title":"<code>generate_prefixed_uuid</code>","text":"<p>Generate a UUID string with the given prefix.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>The prefix to use for the UUID</p> required <p>Returns:</p> Type Description <code>str</code> <p>A UUID string with the given prefix</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the prefix contains an underscore</p> Example <p>Generate a UUID with the prefix \"my_prefix\" <pre><code>from raggy.utilities.ids import generate_prefixed_uuid\n\nuuid = generate_prefixed_uuid(\"schleeb\") # 'schleeb_6be20040-b7e0-4990-b271-394221584a59'\n</code></pre></p>"},{"location":"api_reference/utilities/logging/","title":"Logging","text":"<p>Module for logging utilities.</p>"},{"location":"api_reference/utilities/logging/#raggy.utilities.logging.RaggyLogger","title":"<code>RaggyLogger</code>","text":"<p>A subclass of the standard library <code>logging.Logger</code> class that adds methods for logging with styles and key-value pairs.</p>"},{"location":"api_reference/utilities/logging/#raggy.utilities.logging.get_logger","title":"<code>get_logger</code>  <code>cached</code>","text":"<p>Retrieves a logger with the given name, or the root logger if no name is given.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>The name of the logger to retrieve.</p> <code>None</code> <p>Returns:</p> Type Description <code>RaggyLogger</code> <p>The logger with the given name, or the root logger if no name is given.</p> Example <p>Basic Usage of <code>get_logger</code> <pre><code>from raggy.utilities.logging import get_logger\n\nlogger = get_logger(\"raggy.test\")\nlogger.info(\"This is a test\") # Output: raggy.test: This is a test\n\ndebug_logger = get_logger(\"raggy.debug\")\ndebug_logger.debug_kv(\"TITLE\", \"log message\", \"green\")\n</code></pre></p>"},{"location":"api_reference/utilities/text/","title":"Text","text":""},{"location":"api_reference/utilities/text/#raggy.utilities.text.count_tokens","title":"<code>count_tokens</code>","text":"<p>Counts the number of tokens in the given text using the specified model.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to count tokens in.</p> required <code>model</code> <code>str | None</code> <p>The model to use for token counting. If not provided, the default model is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of tokens in the text.</p>"},{"location":"api_reference/utilities/text/#raggy.utilities.text.detokenize","title":"<code>detokenize</code>","text":"<p>Detokenizes the given tokens using the specified model.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>list[int]</code> <p>The tokens to detokenize.</p> required <code>model</code> <code>str | None</code> <p>The model to use for detokenization. If not provided, the default model is used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The detokenized text.</p>"},{"location":"api_reference/utilities/text/#raggy.utilities.text.extract_keywords","title":"<code>extract_keywords</code>","text":"<p>Extract keywords from the given text using the yake library.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to extract keywords from.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: The keywords extracted from the text.</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If yake is not installed.</p> Example <p>Extract keywords from a text: <pre><code>from raggy.utilities.text import extract_keywords\n\ntext = \"This is a sample text from which we will extract keywords.\"\nkeywords = extract_keywords(text)\nprint(keywords) # ['keywords', 'sample', 'text', 'extract']\n</code></pre></p>"},{"location":"api_reference/utilities/text/#raggy.utilities.text.get_encoding_for_model","title":"<code>get_encoding_for_model</code>","text":"<p>Get the <code>tiktoken</code> encoding for the specified model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str | None</code> <p>The model to get the encoding for. If not provided, the default chat completions model is used (as specified in <code>raggy.settings</code>). If an invalid model is provided, 'gpt-3.5-turbo' is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Encoding</code> <p>tiktoken.Encoding: The encoding for the specified model.</p> Example <p>Get the encoding for the default chat completions model: <pre><code>from raggy.utilities.text import get_encoding_for_model\n\nencoding = get_encoding_for_model() # 'gpt-3.5-turbo' by default\n</code></pre></p>"},{"location":"api_reference/utilities/text/#raggy.utilities.text.hash_text","title":"<code>hash_text</code>  <code>cached</code>","text":"<p>Hash the given text using the xxhash algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to hash.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The hash of the text.</p> Example <p>Hash a single text: <pre><code>from raggy.utilities.text import hash_text\n\ntext = \"This is a sample text.\"\nhash_ = hash_text(text)\nprint(hash_) # 4a2db845d20188ce069196726a065a09\n</code></pre></p>"},{"location":"api_reference/utilities/text/#raggy.utilities.text.slice_tokens","title":"<code>slice_tokens</code>","text":"<p>Slices the given text to the specified number of tokens.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to slice.</p> required <code>n_tokens</code> <code>int</code> <p>The number of tokens to slice the text to.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The sliced text.</p> Example <p>Slice a text to the first 50 tokens: <pre><code>from raggy.utilities.text import slice_tokens\n\ntext = \"This is a sample text.\"*100\nsliced_text = slice_tokens(text, 5)\nprint(sliced_text) # 'This is a sample text.'\n</code></pre></p>"},{"location":"api_reference/utilities/text/#raggy.utilities.text.split_text","title":"<code>split_text</code>","text":"<p>Split a text into a list of strings. Chunks are split by tokens.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to split.</p> required <code>chunk_size</code> <code>int</code> <p>The number of tokens in each chunk.</p> required <code>chunk_overlap</code> <code>float | None</code> <p>The fraction of overlap between chunks.</p> <code>None</code> <code>last_chunk_threshold</code> <code>float | None</code> <p>If the last chunk is less than this fraction of the chunk_size, it will be added to the prior chunk</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: The list of chunks.</p> Example <p>Split a text into chunks of 5 tokens with 10% overlap: <pre><code>from raggy.utilities.text import split_text\n\ntext = \"This is a sample text.\"*3\nchunks = split_text(text, 5, 0.1)\nprint(chunks) # ['This is a sample text', '.This is a sample text', '.This is a sample text.']\n</code></pre></p>"},{"location":"api_reference/utilities/text/#raggy.utilities.text.tokenize","title":"<code>tokenize</code>","text":"<p>Tokenizes the given text using the specified model.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to tokenize.</p> required <code>model</code> <code>str | None</code> <p>The model to use for tokenization. If not provided, the default model is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[int]</code> <p>list[int]: The tokenized text as a list of integers.</p>"},{"location":"api_reference/vectorstores/base/","title":"Base","text":""},{"location":"api_reference/vectorstores/base/#raggy.vectorstores.base.Vectorstore","title":"<code>Vectorstore</code>","text":"<p>Base class for vectorstores.</p> <p>Allows for easy logging and context management.</p> <p>Attributes:</p> Name Type Description <code>_in_context</code> <code>bool</code> <p>Whether the vectorstore is currently in a context.</p> Example <p>Basic Usage of <code>Vectorstore</code> <pre><code>from raggy.vectorstores.base import Vectorstore\n\nclass MyVectorstore(Vectorstore):\n    pass\n\nwith MyVectorstore() as vectorstore:\n    ...\n</code></pre></p>"},{"location":"api_reference/vectorstores/chroma/","title":"Chroma","text":""},{"location":"api_reference/vectorstores/chroma/#raggy.vectorstores.chroma.Chroma","title":"<code>Chroma</code>","text":"<p>A wrapper for chromadb.Client.</p>"},{"location":"api_reference/vectorstores/chroma/#raggy.vectorstores.chroma.Chroma.upsert_batched","title":"<code>upsert_batched</code>  <code>async</code>","text":"<p>Upsert documents in batches concurrently.</p>"},{"location":"api_reference/vectorstores/chroma/#raggy.vectorstores.chroma.query_collection","title":"<code>query_collection</code>","text":"<p>Query a Chroma collection.</p>"},{"location":"api_reference/vectorstores/tpuf/","title":"TurboPuffer","text":""},{"location":"api_reference/vectorstores/tpuf/#raggy.vectorstores.tpuf.TurboPuffer","title":"<code>TurboPuffer</code>","text":"<p>Wrapper for turbopuffer.Namespace as a context manager.</p> <p>Attributes:</p> Name Type Description <code>namespace</code> <code>str</code> <p>The namespace to use for the TurboPuffer instance.</p> <p>Examples:</p> <p>Upsert documents to a namespace: <pre><code>from raggy.documents import Document\nfrom raggy.vectorstores.tpuf import TurboPuffer\n\nwith TurboPuffer() as tpuf: # default namespace is \"raggy\"\n    tpuf.upsert(documents=[Document(id=\"1\", text=\"Hello, world!\")])\n</code></pre></p> <p>Query a namespace: <pre><code>from raggy.vectorstores.tpuf import TurboPuffer\n\nwith TurboPuffer() as tpuf:\n    result = tpuf.query(text=\"Hello, world!\")\n    print(result)\n</code></pre></p>"},{"location":"api_reference/vectorstores/tpuf/#raggy.vectorstores.tpuf.TurboPuffer.upsert_batched","title":"<code>upsert_batched</code>  <code>async</code>","text":"<p>Upsert documents in batches concurrently.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>Sequence[Document]</code> <p>Sequence of documents to upsert</p> required <code>batch_size</code> <code>int</code> <p>Maximum number of documents per batch</p> <code>100</code> <code>max_concurrent</code> <code>int</code> <p>Maximum number of concurrent upsert operations</p> <code>8</code>"},{"location":"api_reference/vectorstores/tpuf/#raggy.vectorstores.tpuf.TurboPufferSettings","title":"<code>TurboPufferSettings</code>","text":"<p>Settings for the TurboPuffer vectorstore.</p>"},{"location":"api_reference/vectorstores/tpuf/#raggy.vectorstores.tpuf.multi_query_tpuf","title":"<code>multi_query_tpuf</code>","text":"<p>searches a Turbopuffer namespace for the given queries</p>"},{"location":"api_reference/vectorstores/tpuf/#raggy.vectorstores.tpuf.query_namespace","title":"<code>query_namespace</code>","text":"<p>Query a TurboPuffer namespace.</p>"},{"location":"examples/","title":"Example Gallery","text":"<p>Here are some practical examples of using <code>raggy</code> in real-world scenarios.</p>"},{"location":"examples/#chat-with-content","title":"Chat with Content","text":"<p>Ye old \"chat your data\" examples.</p>"},{"location":"examples/#chat-with-a-website","title":"Chat with a Website","text":"<pre><code>uv run examples/chat_with_X/website.py \"let's chat about docs.astral.sh/uv\"\n</code></pre>"},{"location":"examples/#chat-with-a-github-repo","title":"Chat with a GitHub Repo","text":"<pre><code>uv run examples/chat_with_X/repo.py \"let's chat about astral-sh/uv\"\n</code></pre>"},{"location":"examples/#refresh-vectorstores","title":"Refresh Vectorstores","text":"<p>A <code>prefect</code> flow to gather documents from sources of knowledge, embed them and put them in a vectorstore.</p>"},{"location":"examples/#refresh-turbopuffer","title":"Refresh TurboPuffer","text":"<pre><code>uv run examples/refresh_vectorstore/tpuf_namespace.py\n</code></pre>"},{"location":"examples/#refresh-chroma","title":"Refresh Chroma","text":"<pre><code>uv run examples/refresh_vectorstore/chroma_collection.py\n</code></pre>"},{"location":"welcome/installation/","title":"Installation","text":"<p>To install the package from PyPI:</p> <pre><code># using pip\npip install raggy\n\n# using uv\nuv pip install raggy\n</code></pre> <p>What's <code>uv</code>?</p> <p>Well I'm glad you asked \ud83d\ude42</p>"},{"location":"welcome/installation/#requirements","title":"Requirements","text":"<p><code>raggy</code> unapolagetically requires python 3.10+.</p>"},{"location":"welcome/installation/#optional-dependencies","title":"Optional dependencies","text":"<p><code>raggy</code> offers a few optional dependencies that can be installed as extras:</p> <ul> <li><code>chroma</code> - for using the <code>Chroma</code> vectorstore</li> <li><code>tpuf</code> - for using the (managed) <code>Turbopuffer</code> vectorstore</li> <li><code>pdf</code> - for parsing PDFs</li> </ul>"},{"location":"welcome/installation/#development","title":"Development","text":"<p>Clone the repo:</p> <pre><code>git clone https://github.com/zzstoatzz/raggy.git\ncd raggy\n</code></pre> <p>Install the package in editable mode:</p> <pre><code>pip install -e \".[dev]\"\n</code></pre>"},{"location":"welcome/tutorial/","title":"Tutorial","text":""},{"location":"welcome/tutorial/#loading-documents","title":"Loading documents","text":"<pre><code>from raggy.loaders.web import SitemapLoader\n\nraggy_documentation_loader = SitemapLoader(\n    urls=[\"https://zzstoatzz.github.io/raggy/sitemap.xml\"],\n    exclude=[\"api-ref\", \"/events/\"],\n)\ndocuments = await raggy_documentation_loader.load()\n\nprint(documents[0])\n</code></pre>"},{"location":"welcome/tutorial/#adding-documents-to-a-vectorstore","title":"Adding documents to a vectorstore","text":"<p>New in 0.2.0</p> <p>Vectorstore operations are now synchronous by default, with async batching available via <code>upsert_batched</code>.</p> <pre><code>from raggy.vectorstores.tpuf import TurboPuffer\n\nwith TurboPuffer(namespace=\"my_documents\") as vectorstore:\n    # Synchronous operation\n    vectorstore.upsert(documents)\n\n    # Async batched usage for large document sets\n    await vectorstore.upsert_batched(\n        documents,\n        batch_size=100,\n        max_concurrent=8\n    )\n</code></pre>"},{"location":"welcome/tutorial/#querying-the-vectorstore","title":"Querying the vectorstore","text":"<pre><code>from raggy.vectorstores.tpuf import query_namespace, multi_query_tpuf\n\n# Single query\nresult = query_namespace(\"how do I get started with raggy?\")\nprint(result)\n\n# Multiple related queries for better coverage\nresult = multi_query_tpuf([\n    \"how to install raggy\",\n    \"basic raggy usage\",\n    \"raggy getting started\"\n])\nprint(result)\n</code></pre>"},{"location":"welcome/tutorial/#real-world-examples","title":"Real-world examples","text":"<ul> <li>Chat with a GitHub repo</li> <li>Chat with a website</li> <li>Refresh a vectorstore</li> </ul>"}]}